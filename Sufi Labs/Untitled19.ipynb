{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXiv5eQgzrL77rDtmeqmua"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"GZeKGrud9YL9","executionInfo":{"status":"error","timestamp":1713238886336,"user_tz":-300,"elapsed":1942,"user":{"displayName":"Sufyan Mumtaz","userId":"05079447856688318479"}},"outputId":"d3134976-b032-45c1-a6e4-5409df539ae7"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'Imputer' from 'sklearn.preprocessing' (/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6e97a094e9cf>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#handling missing data(Replacing missing data with the mean value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as nm\n","import matplotlib.pyplot as mtp\n","import pandas as pd\n","\n","#importing datasets\n","data_set= pd.read_csv('/content/Data (2).csv')\n","\n","#Extracting Independent Variable\n","x= data_set.iloc[:, :-1].values\n","\n","#Extracting Dependent variable\n","y= data_set.iloc[:, 3].values\n","\n","#handling missing data(Replacing missing data with the mean value)\n","from sklearn.preprocessing import Imputer\n","imputer= Imputer(missing_values ='NaN', strategy='mean', axis = 0)\n","\n","#Fitting imputer object to the independent varibles x.\n","imputerimputer= imputer.fit(x[:, 1:3])\n","\n","#Replacing missing data with the calculated mean value\n","x[:, 1:3]= imputer.transform(x[:, 1:3])\n","\n","#for Country Variable\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","label_encoder_x= LabelEncoder()\n","x[:, 0]= label_encoder_x.fit_transform(x[:, 0])\n","\n","#Encoding for dummy variables\n","onehot_encoder= OneHotEncoder(categorical_features= [0])\n","x= onehot_encoder.fit_transform(x).toarray()\n","\n","#encoding for purchased variable\n","labelencoder_y= LabelEncoder()\n","y= labelencoder_y.fit_transform(y)\n","\n","# Splitting the dataset into training and test set.\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)\n","\n","#Feature Scaling of datasets\n","from sklearn.preprocessing import StandardScaler\n","st_x= StandardScaler()\n","x_train= st_x.fit_transform(x_train)\n","x_test= st_x.transform(x_test)"]}]}